{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "from shapely.geometry  import shape, Point\n",
    "from geopy.geocoders import Nominatim\n",
    "import numpy as np\n",
    "import meteostat as ms\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "from geopy import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREDS = \"C:/Users/tkkim/gcp_keys/capstone-team51-366963bafc54.json\"\n",
    "storage_client = storage.Client.from_service_account_json(json_credentials_path=CREDS,project='capstone-team51')\n",
    "bq_client = bigquery.Client.from_service_account_json(json_credentials_path=CREDS,project='capstone-team51')\n",
    "#client = bigquery.Client(project='capstone-team51')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"test_tk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = storage_client.get_bucket('capstone-team51-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(lat, long):\n",
    "    if lat == 0 or long == 0:\n",
    "        return 'No Lat/Long', 999999\n",
    "    else:\n",
    "        try:\n",
    "            input_latlong = (long,lat)\n",
    "            #distance_list = []\n",
    "            pdf = stations_df.copy()\n",
    "            pdf['distance'] = pdf.apply(lambda x: distance.distance(input_latlong, (x.LONGITUDE,x.LATITUDE)).miles, axis=1)\n",
    "            nearest_station = pdf.iloc[pdf['distance'].idxmin()]\n",
    "            #print(nearest_station)\n",
    "            return nearest_station['ADDRESS'], nearest_station['distance']\n",
    "            \"\"\"for row in POLICE_DF.iterrows():\n",
    "                distance_holder = {}\n",
    "                station_latlong = [row['LATITUDE'], row['LONGITUDE']]\n",
    "                distance_holder['station'] = row['ADDRESS']\n",
    "                distance_holder['distance'] = distance.distance(input_latlong, station_latlong).miles\n",
    "\n",
    "                distance_list.append(distance_holder)\n",
    "                distance_df = pd.DataFrame(distance_list)\n",
    "                nearest_station = distance_df.iloc[distance_df['distance'].idxmin()]\n",
    "                print(f\"{distance_df.head()}\")\n",
    "                return nearest_station['station'], nearest_station['distance'] \"\"\"\n",
    "        except Exception as e:\n",
    "            #print(e)\n",
    "            return 'Error something something', 999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commarea_env(df_, commarea):\n",
    "    dataframe = df_.copy()\n",
    "    dataframe['community_area']=''\n",
    "    for row in dataframe.index:\n",
    "        point = Point(dataframe.loc[row,'longitude'],dataframe.loc[row,'latitude'])\n",
    "        #print(point.xy)\n",
    "        for feature in commarea['features']:\n",
    "            polygon = shape(feature['geometry'])\n",
    "            if polygon.contains(point):\n",
    "                dataframe.loc[row, 'community_area'] = feature['properties']['area_numbe']\n",
    "                \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getpoint(address):\n",
    "    loc = geolocator.geocode(address)\n",
    "    latlong = [loc.latitude, loc.longitude]\n",
    "    point = Point(latlong[1], latlong[0])   \n",
    "    return point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findarea(point, commarea):    \n",
    "    for feature in commarea['features']:\n",
    "        polygon = shape(feature['geometry'])\n",
    "        if polygon.contains(point):\n",
    "           return feature['properties']['area_numbe']\n",
    "        else:\n",
    "            continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_gcs(prefix, filename):\n",
    "    df = pd.DataFrame()\n",
    "    for blob in storage_client.list_blobs('capstone-team51-data', prefix=prefix, delimiter='/'):\n",
    "        #print(blob.name)\n",
    "        if filename in blob.name:\n",
    "            #print(blob.name)\n",
    "            data = blob.download_as_bytes()\n",
    "            smalldf = pd.read_csv(io.BytesIO(data))\n",
    "            #print(smalldf)\n",
    "            df = pd.concat([df, smalldf])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = load_df_gcs('raw_crimes/', 'chunk')\n",
    "three11_df = load_df_gcs('raw_311/', 'chunk')\n",
    "env_df = load_df_gcs('raw_environmental/', 'chunk')\n",
    "weather_df = load_df_gcs('raw_weather/', 'data')\n",
    "offenders_df = load_df_gcs('supporting/off_commarea/', 'csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stations_blob = bucket.blob('supporting_data/Police_Stations_20240120.csv').download_as_bytes()\n",
    "stations_df = load_df_gcs('supporting/', 'Police_Stations_20240120.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "commarea = json.loads(bucket.blob('supporting/geojsons/Boundaries - Community Areas (current).geojson').download_as_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_df_ca = get_commarea_env(env_df, commarea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_df_ca['community_area'] = np.where(env_df_ca['community_area'] == '', 9999, env_df_ca['community_area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['complaint_id', 'complaint_type', 'address', 'street_number',\n",
       "       'direction', 'street_name', 'street_type', 'inspector',\n",
       "       'complaint_date', 'inspection_log', 'data_source', 'modified_date',\n",
       "       'latitude', 'longitude', 'location.type', 'location.coordinates',\n",
       "       'complaint_detail', 'community_area'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_df_ca.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dph env complaints\n",
    "\n",
    "grouped_complaints_by_commarea = env_df_ca.groupby(['complaint_date','community_area']).agg(total_complaints_in_ca=('complaint_id','count')).reset_index()\n",
    "grouped_complaints_by_commarea.rename(columns={'complaint_date':'date'}, inplace=True)\n",
    "grouped_complaints_by_commarea['date'] = pd.to_datetime(grouped_complaints_by_commarea['date']).dt.date\n",
    "grouped_complaints_by_commarea['community_area'] = grouped_complaints_by_commarea['community_area'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 311 complaints\n",
    "grouped_date = three11_df.groupby([three11_df['created_date'],'community_area','sr_type']).agg(total_count=('sr_number','count')).reset_index()\n",
    "pivoted = grouped_date.pivot_table(index=['created_date','community_area'],columns='sr_type',values='total_count',aggfunc='sum').fillna(0).reset_index()\n",
    "pivoted['created_date'] = pd.to_datetime(pivoted['created_date'])\n",
    "pivoted.rename(columns={'created_date':'date'}, inplace=True)\n",
    "pivoted['community_area'] = pivoted['community_area'].astype(int)\n",
    "pivoted['date'] = pd.to_datetime(pivoted['date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge offenders in\n",
    "big_df = base_df.copy().merge(offenders_df, how='left', on='community_area')\n",
    "big_df['date'] = pd.to_datetime(big_df['date']).dt.date\n",
    "big_df['community_area'] = big_df['community_area'].fillna(9999).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge weather in\n",
    "weather_df.rename(columns={'time':'date'}, inplace=True)\n",
    "weather_df['date'] = pd.to_datetime(weather_df['date']).dt.date\n",
    "big_df['date'] = pd.to_datetime(big_df['date']).dt.date\n",
    "big_df = big_df.merge(weather_df, how='left', on='date')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
