{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your data folder\n",
    "desti_folder = './data'\n",
    "\n",
    "# give your socrata token\n",
    "token = 'YOURTOKENHERE'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_start_date = '2019-01-01'\n",
    "crime_end_date = '2023-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "envcomplaint_start_date = '2019-01-01'\n",
    "envcomplaint_end_date = '2023-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(desti_folder, exist_ok=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now()\n",
    "timestamp = timestamp.strftime(\"%Y-%m-%d-%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(name, db, maxrows, parameters):\n",
    "    # some key info\n",
    "    db_id = db\n",
    "    limit = maxrows\n",
    "    i = 0\n",
    "    offset_counter = 0\n",
    "    pickle = True\n",
    "    data_name = name\n",
    "    # dict for logging\n",
    "    log_dict = {}\n",
    "\n",
    "    # base url for the request\n",
    "    baseurl = (\"https://data.cityofchicago.org/resource/\"\n",
    "            f\"{db_id}.json?\")\n",
    "\n",
    "    while pickle:\n",
    "        #set our params\n",
    "        # note that you have to URL econde \n",
    "        params = parameters + (\n",
    "            f\"&$limit={limit}\"\n",
    "            f\"&$offset={offset_counter}\"\n",
    "            #f\"&$$app_token={token}\"\n",
    "        )\n",
    "        \n",
    "        # make the request \n",
    "        data_req = requests.get(baseurl+params)\n",
    "\n",
    "        # convert to json\n",
    "        data_json = data_req.json()\n",
    "\n",
    "        # make it a df\n",
    "        df = pd.json_normalize(data_json)\n",
    "\n",
    "        # write df\n",
    "        \n",
    "        \n",
    "        # log\n",
    "        minilog = {}\n",
    "        minilog['records'] = df.shape[0]\n",
    "        minilog['chunk'] = i\n",
    "        minilog['status'] = data_req.status_code\n",
    "        minilog['offset'] = offset_counter\n",
    "        log_dict[f'run_{i}'] = minilog\n",
    "        log_df = pd.DataFrame.from_dict(log_dict,orient='index')\n",
    "        \n",
    "        if df.shape[0] == 0:\n",
    "            break\n",
    "        else:\n",
    "            df.to_json(f'{desti_folder}/{data_name}_chunk_{i}.json',orient='records', lines=True)\n",
    "            log_df.to_csv(f'{desti_folder}/{data_name}_{timestamp}_log.csv')\n",
    "\n",
    "        # increment the chunk count\n",
    "        print(i)\n",
    "        i += 1\n",
    "\n",
    "        # increment the offset\n",
    "        offset_counter += limit\n",
    "\n",
    "        # check if we need to end the loop\n",
    "        if df.shape[0] == 0:\n",
    "            pickle = False\n",
    "        elif data_req.status_code == 200:\n",
    "            pickle = True\n",
    "        else: \n",
    "            pickle = False\n",
    "            print(data_req.status_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "crime_params = (\n",
    "            f\"$where=DATE%20BETWEEN%20%27{crime_start_date}T00%3A00%3A00.000%27%20AND%20%27{crime_end_date}T23%3A59%3A59.000%27\"\n",
    "            f\"&$order=DATE\"\n",
    "            #f\"&$$app_token={token}\"\n",
    "            )\n",
    "\n",
    "get_data('crime5', 'ijzp-q8t2', 500000, crime_params)\n",
    "\n",
    "\n",
    "env_params = (\n",
    "            f\"$where=complaint_date%20BETWEEN%20%27{envcomplaint_start_date}T00%3A00%3A00.000%27%20AND%20%27{envcomplaint_end_date}T23%3A59%3A59.000%27\"\n",
    "            f\"&$order=complaint_date\"\n",
    "            #f\"&$$app_token={token}\"\n",
    "            )\n",
    "\n",
    "get_data('envcomplaint5', 'fypr-ksnz', 500000, env_params)\n",
    "\n",
    "offenders_params = (\n",
    "    f\"$where=block%20not%20like%20%27%25deport%25%27\"\n",
    "            #f\"&$$app_token={token}\"\n",
    "            )\n",
    "\n",
    "get_data('offenders', 'vc9r-bqvy', 500000, offenders_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
