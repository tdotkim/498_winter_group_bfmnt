{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "from shapely.geometry  import shape, Point\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"test_tk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./results', exist_ok=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../download_with_python/data/'\n",
    "cur_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(data_path)\n",
    "files = glob.glob(\"*.json\")\n",
    "os.chdir(cur_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_dict = {}\n",
    "offenders_dict = {}\n",
    "env_dict = {}\n",
    "i = 0\n",
    "\n",
    "for file in files:\n",
    "    name = file.split(sep=\"_\")[0]\n",
    "    if name == 'crime':\n",
    "        crimes_dict[name+f'_{i}'] = pd.read_json((data_path+file), lines=True)\n",
    "    elif name == 'offenders':\n",
    "        offenders_dict[name+f'_{i}'] = pd.read_json((data_path+file), lines=True)\n",
    "        # drop registered as homeless offenders\n",
    "        offenders_dict[name+f'_{i}'] = offenders_dict[name+f'_{i}'][~(offenders_dict[name+f'_{i}']['block'] == '(registered as homeless)')]\n",
    "        # replace anonymized house number with 0 (replaces X with 0)\n",
    "        offenders_dict[name+f'_{i}']['block'] = offenders_dict[name+f'_{i}']['block'].str.replace('X','0') + ' CHICAGO'\n",
    "    elif name == 'envcomplaint':\n",
    "        env_dict[name+f'_{i}'] = pd.read_json((data_path+file), lines=True)\n",
    "    else:\n",
    "        print(f'error on {file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# make merger function to merge like for like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define geojsons\n",
    "with open('../../geojsons/Boundaries - Community Areas (current).geojson') as f:\n",
    "    commarea = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df(dictionary):\n",
    "    merged_df = pd.DataFrame()\n",
    "    for datfram in dictionary:\n",
    "        merged_df= pd.concat([merged_df,dictionary[datfram]],axis=0)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_crimes = merge_df(crimes_dict)\n",
    "merged_offenders = merge_df(offenders_dict)\n",
    "merged_envcomplaints = merge_df(env_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commarea_env(dataframe):\n",
    "    dataframe['neighborhood']=''\n",
    "    for row in dataframe.index:\n",
    "        point = Point(dataframe['location.coordinates'][row][0],dataframe['location.coordinates'][row][1])\n",
    "        for feature in commarea['features']:\n",
    "            polygon = shape(feature['geometry'])\n",
    "            if polygon.contains(point):\n",
    "                dataframe['neighborhood'][row] = feature['properties']['community']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getlatlong(dataframe):\n",
    "    for row in dataframe.index:\n",
    "        try:\n",
    "            location = geolocator.geocode(dataframe['block'][row])\n",
    "            latlong = [location.latitude, location.longitude]\n",
    "            point = Point(latlong[1], latlong[0])\n",
    "        except:\n",
    "            dataframe['neighborhood'][row] = 'no match to osm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commarea_offenders(dataframe):\n",
    "    dataframe['neighborhood']=''\n",
    "    i=0\n",
    "    for row in dataframe.index:\n",
    "        try:\n",
    "            location = geolocator.geocode(dataframe['block'][row])\n",
    "            latlong = [location.latitude, location.longitude]\n",
    "            point = Point(latlong[1], latlong[0])\n",
    "            for feature in commarea['features']:\n",
    "                polygon = shape(feature['geometry'])\n",
    "                if polygon.contains(point):\n",
    "                    dataframe['neighborhood'][row] = feature['properties']['area_numbe']\n",
    "                else:\n",
    "                    dataframe['neighborhood'][row] = 'no match to neighborhood'\n",
    "        except:\n",
    "            dataframe['neighborhood'][row] = 'no match to osm'\n",
    "        print(f'{round((i/dataframe.shape[0]),4)*100}% done')\n",
    "        i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = geolocator.geocode(merged_offenders['block'][10])\n",
    "latlong = [location.latitude, location.longitude]\n",
    "point = Point(latlong[1], latlong[0])\n",
    "for feature in commarea['features']:\n",
    "    polygon = shape(feature['geometry'])\n",
    "if polygon.contains(point):\n",
    "    merged_offenders['neighborhood'][5] = feature['properties']['area_numbe']\n",
    "else:\n",
    "    merged_offenders['neighborhood'][5] = 'no match to neighborhood'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_commarea_env(merged_envcomplaints)\n",
    "get_commarea_offenders(merged_offenders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_crimes.to_csv('./results/crimes_cleaned.csv', index=False)\n",
    "merged_offenders.to_csv('./results/offeders_cleaned.csv', index=False)\n",
    "merged_envcomplaints.to_csv('./results/crimes_envcomplaints.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_offenders_by_commarea = merged_offenders.groupby('neighborhood').agg(total_offenders_in_ca=('last','count')).reset_index()\n",
    "grouped_offenders_by_commarea.to_csv('./results/offenders_by_neighborhood.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_complaints_by_commarea = merged_envcomplaints.groupby('neighborhood').agg(total_complaints_in_ca=('complaint_id','count')).reset_index()\n",
    "grouped_complaints_by_commarea.to_csv('./results/envcomplaints_by_neighborhood.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_offenders_by_commarea.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_crimes.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = merged_crimes.merge(grouped_offenders_by_commarea, how='left', on='neighborhood')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
